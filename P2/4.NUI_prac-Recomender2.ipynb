{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctiques de Nous Usos de la Informàtica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nom de les persones del grup:** Xavi Cano & Orlando Manjarrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 2. Recomanadors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcció d'un recomanador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lectura de dades\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "users = pd.read_table('ml-1m/users.dat', sep='::', header=None, names=unames, engine='python')\n",
    "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_table('ml-1m/ratings.dat', sep='::', header=None, names=rnames, engine='python')\n",
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_table('ml-1m/movies.dat', sep='::', header=None, names=mnames, engine='python')\n",
    "\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[data.user_id < 100]\n",
    "data = data[data.movie_id < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alerta**: Les implementacions dels exercicis 6, 7 i 8 poden tardar molt en executar-se, considera fer-ho en un subset de les dades originals. En la 1a cel·la:\n",
    "```\n",
    "    data = data[data.user_id < 100]\n",
    "    data = data[data.movie_id < 100]\n",
    "```\n",
    "El codi anterior limitaria les dades a 100 usuaris i 100 películes. Recorda re-executar les cel·les.\n",
    "\n",
    "Com a guia, una implementació que usi N usuaris i películes, per l'exercici 6, ot arribar a trigar:\n",
    "\n",
    "* N=100, 5 segons a 60 segons\n",
    "* N=1000, 15 minuts a 1 hora\n",
    "* N=10000, 20 hores a 60 hores\n",
    "\n",
    "segons la implementació utilitzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El següent codi, donat el conjunt de dades, construeix un conjunt d'entrenament i un conjunt  de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 11)\n",
      "(135, 11)\n"
     ]
    }
   ],
   "source": [
    "# generem subconjunts de training i test\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.2)),\n",
    "                                   replace=False)\n",
    "    df.ix[sampled_ids, 'for_testing'] = True\n",
    "    return df\n",
    "\n",
    "data['for_testing'] = False\n",
    "grouped = data.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "movielens_train = data[grouped.for_testing == False]\n",
    "movielens_test = data[grouped.for_testing == True]\n",
    "print movielens_train.shape\n",
    "print movielens_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La següent funció `evaluate(estimate)`, donat un conjunt de dades d'entrenament i un conjunt de dades de test ens avalua la precisió d'un sistema de recomanació que li passem per paràmetre. Per a cadascun dels elements del conjunt de test haurem de pronosticar el seu valor i comparar-lo amb el valor real que l'usuari li ha asignat. La mesura que utilizarem per avaluar el sistema és la root-mean-square error (rsme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definim una funció per avaluar el resultat de la recomanació.\n",
    "\n",
    "def compute_rmse(y_pred, y_true):\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "def evaluate(estimate,test=movielens_test):\n",
    "    ids_to_estimate = zip(test['user_id'], test['movie_id'])\n",
    "    estimated = np.array([estimate(u,i) for (u,i) in ids_to_estimate])\n",
    "    real = test.rating.values\n",
    "    nans = np.isnan(estimated)\n",
    "    return compute_rmse(estimated[~nans], real[~nans])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 4\n",
    "\n",
    "+ Construeix dues funcions, `dist_euclid(x,y)` i `coef_pearson(x,y)`, que implementin la distància Euclidiana i el coeficient de correlació de Pearson entre dos vectors usant funcions de pandas. \n",
    "\n",
    "+ Escriu les funcions que calculin la semblança entre dos series d'un DataFrame de Pandas. S'utiltizaran per calcular les similituds entre usuaris o entre items:\n",
    "\n",
    "    + ``def sim_euclid (data_frame, row1, row2)``\n",
    "    Calcula els vectors representatius de cada fila, C1 i C2, amb les puntuacions de les columnes que estan presents en ambdós files. En el cas dels usuaris (files), això implica trobar les películes (columnes) que han puntuat tots dos.<br />Si no hi ha puntuacions en comú, retornar 0. En cas contrari, retornar ``1/(1+dist_euclid(C1, C2))``\n",
    "\n",
    "    + ``def sim_pearson (data_frame, row1, row2)``\n",
    "    Calcular els vectors representatius de cada fila, C1 i C2, amb les puntuacions de les columnes que estan presents en ambdós files.<br />Si no hi ha puntuacions en comú, retornar 0. Retornar ``coef_pearson(C1,C2)``\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Returns the euclidean distance of two vectors\n",
    "def dist_euclid(x, y):\n",
    "    if len(x) == len(y):\n",
    "        resultado = math.sqrt(sum([(x[i]-y[i])**2 for i in range(0,len(x))]))\n",
    "    else:\n",
    "        return 0\n",
    "    return resultado\n",
    "\n",
    "# Returns the Pearson correlation of two vectors \n",
    "def coef_pearson(x, y):\n",
    "    if len(x) == len(y):\n",
    "        denominador = math.sqrt(sum([(x[i]-np.mean(x))**2 for i in range(0,len(x))])) * math.sqrt(sum([(y[i]-np.mean(y))**2 for i in range(0,len(y))]))\n",
    "        # Si el denominador es 0 nos evitamos calcular l numerador\n",
    "        if denominador == 0:\n",
    "            return 0\n",
    "        else :\n",
    "            numerador = sum([(x[i]-np.mean(x))*(y[i]-np.mean(y)) for i in range(0,len(x))])\n",
    "            resultado = numerador/denominador \n",
    "    else:\n",
    "        return 0\n",
    "    return abs(resultado)\n",
    "\n",
    "# Returns a distance-based similarity score for person1 and person2 based on euclidean distance\n",
    "def sim_euclid(data_frame, row1, row2):\n",
    "    #Obtenim el dataFrames amb les pelicules i votació de cada usuari\n",
    "    data_usr1 = data_frame[ data_frame['user_id'] == row1][['movie_id','rating']]\n",
    "    data_usr2 = data_frame[ data_frame['user_id'] == row2][['movie_id','rating']]\n",
    "    #Finalment obtenim únicament les votacions de les pel·lícules evaluades per els dos usuaris\n",
    "    ints = pd.merge(data_usr1, data_usr2, how='inner',on='movie_id', suffixes=('_usr1', '_usr2')) \n",
    "    return 1/(1+dist_euclid(ints['rating_usr1'], ints['rating_usr2']))\n",
    "\n",
    "# Returns a distance-based similarity score for person1 and person2 based on pearson distance\n",
    "def sim_pearson(data_frame, row1, row2):\n",
    "    #Obtenim el dataFrames amb les pelicules i votació de cada usuari\n",
    "    data_usr1 = data_frame[ data_frame['user_id'] == row1][['movie_id','rating']]\n",
    "    data_usr2 = data_frame[ data_frame['user_id'] == row2][['movie_id','rating']]\n",
    "    #Finalment obtenim únicament les votacions de les pel·lícules evaluades per els dos usuaris\n",
    "    ints = pd.merge(data_usr1, data_usr2, how='inner',on='movie_id', suffixes=('_usr1', '_usr2'))\n",
    "    return coef_pearson(ints['rating_usr1'], ints['rating_usr2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests de les funcions, pots realitzar modificacions prèvies a les taules (per exemple, agrupar o pivotar) per accelerar el procés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "0.956606702325\n",
      "1.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con dos vectores para comprobar el buen funcionamiento \n",
    "# de las funciones dist_euclid y el coef_pearson\n",
    "print dist_euclid ([2,2,2,2],[1,1,1,1])\n",
    "print coef_pearson ([2,9,8,2],[1,7,7,3])\n",
    "\n",
    "# Execute functions\n",
    "print sim_euclid(data, 1, 2)\n",
    "print sim_pearson(data, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 5\n",
    "\n",
    "+ Feu dues funcions, ``get_best_euclid(data_frame, user, n)`` i ``get_best_pearson(data_frame, user, n)``, que retornin els ``n`` usuaris més semblants segons aquestes dues mesures de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return the N most similar users to a given user based on euclidean distance\n",
    "def get_best_euclid(data_frame, user, n):\n",
    "    # Per tal de fer-ho més eficient reduim el DataFrame a unicament les pel·licules votades per 'user'\n",
    "    data2 = pd.merge(data_frame,data_frame[data_frame['user_id']==user][['movie_id','title']],how='inner',on='movie_id')[['user_id','movie_id','rating']]\n",
    "    # Obtenim una llista dels usuaris excepte el propi a comparar\n",
    "    users = set(data2[data2['user_id'] != user]['user_id'])\n",
    "    # Calculem la dist. Euclid. entre usuaris (i,user) per tots els users necessaris i els ordenem.\n",
    "    rank = [(sim_euclid(data2,user,i),i) for i in users]   \n",
    "    rank = sorted(rank, key=lambda pearson_rtg: pearson_rtg[0], reverse=True)\n",
    "    return [ rank[i] for i in range(n) ]\n",
    "    \n",
    "# return the N most similar users to a given user based on pearson correlation\n",
    "def get_best_pearson(data_frame, user, n):\n",
    "    # Per tal de fer-ho més eficient reduim el DataFrame a unicament les pel·licules votades per 'user'\n",
    "    data2 = pd.merge(data_frame,data_frame[data_frame['user_id']==user][['movie_id','title']],how='inner',on='movie_id')[['user_id','movie_id','rating']]\n",
    "    # Obtenim una llista dels usuaris excepte el propi a comparar\n",
    "    users = set(data2[data2['user_id'] != user]['user_id'])\n",
    "    # Calculem el coef entre usuaris (i,user) per tots els users.\n",
    "    rank = [(sim_pearson(data2,user,i),i) for i in users]\n",
    "    rank = sorted(rank, key=lambda pearson_rtg: pearson_rtg[0], reverse=True)\n",
    "    return [ rank[i] for i in range(n) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 9), (1.0, 19), (1.0, 34), (1.0, 36), (1.0, 44)]\n",
      "[(0, 6), (0, 8), (0, 9), (0, 10), (0, 18)]\n"
     ]
    }
   ],
   "source": [
    "# Execute functions\n",
    "# Aquestes funcions poden trigar a executar-se; feu proves primer amb una part petita de la base de dades.\n",
    "\n",
    "print get_best_euclid(data, 1, 5)\n",
    "print get_best_pearson(data, 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 6\n",
    "\n",
    "En l'exercici 6 i 7 es desenvoluparà un sistema de recomanació basat en usuaris i en ítems, respectivament.\n",
    "\n",
    "El codi donat, que es basa en 3 classes, és la recomenada per fer-ho òptim i reaprofitar el màxim de codi, però s'acceptaran solucions que no la segueixin, sempre hi quan respectin el mètode \"estimate\" explicat més abaix i funcionin de forma correcte.\n",
    "\n",
    "#### `CollaborativeFiltering`\n",
    "\n",
    "Una classe base, comuna en els 2 recomanadors, que implementarà:\n",
    "  \n",
    "  * `__init__`: Rep com a paràmetres el dataframe (que constarà de `user_id`, `movie_id` i `rating`), la funció de semblança (Euclidiana o Pearson) que volem usar i un paràmetre `M` que indica el tamany que tindrà la matriu de similituds.\n",
    "  \n",
    "  * `precompute`: Generar per cada estimació la semblança entre 2 usuaris o items seria molt costós i faria l'algorisme molt lent, per tant, aquesta funció omplirà la taula MxM (on M es el número de usuaris o items, segons el recomanador) amb el coeficient de semblança.\n",
    "      * Nota: La taula es un DataFrame de Pandas, per tant accedirem als element fent servir l'indexat de Pandas (que correspon al id del user/movie, i no a la posició 0...i)\n",
    "  \n",
    "  * `estimate`: s'encarrega de donar la predicció, en aquest cas donat un usuari i una pel·lícula estimar el seu rating.\n",
    "    + Nota 1: Si un `user_id` o `movie_id` no es troba en el DataFrame, cal retornar \"np.NAN\"\n",
    "    + Nota 2: En el recomenador d'usuaris, s'ha d'evitar comparar `user_id` a ell mateix. De la mateixa forma, en el d'items evitarem comparar un `movie_id` amb sí mateix.\n",
    "\n",
    "#### `UserRecomender`\n",
    "\n",
    "Recomanador basat en usuaris que hereta de `CollaborativeFiltering`. Implementarà:\n",
    "\n",
    "  * `__init__`: Pot realitzar transformacions al DataFrame\n",
    "  \n",
    "#### `ItemRecomender`\n",
    "\n",
    "Recomanador basat en items que hereta de `CollaborativeFiltering`. Implementarà:\n",
    "\n",
    "  * `__init__`: Pot realitzar transformacions al DataFrame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "class CollaborativeFiltering(object):\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, data, M, similarity=sim_pearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method = similarity # Gets recommendations for a person by using a weighted average\n",
    "        self.df = data \n",
    "        self.sim = pd.DataFrame(0.0, index=M, columns=M)\n",
    "        # Diccionario de las peliculas vistas por cada usuario para agilizar los calculos de busqueda \n",
    "        self.dicUser={} # key usuario y contiene sus peliculs y ratings de estas\n",
    "        users=self.df.user_id.unique() # Obtener todos los ids de los usuarios del data\n",
    "        for us in users: # Se guardan los valores de rating i movie_id de cada usuario para no buscar mas al DataFrame\n",
    "            self.dicUser[us]=self.df.ix[self.df['user_id']==us,['rating','movie_id']].sort(ascending=False,columns='rating') #Ordre Rating\n",
    "        # Diccionario de los usuarios y ratings de cada pelicula para agilizar los calculos de busqueda\n",
    "        self.dicPelis={}#key pelicula y contiene sus ratings de cada usuario\n",
    "        pelis=self.df.movie_id.unique() #Obtener todos los ids de la peliculas del data\n",
    "        for film in pelis: #Se guardan los valores de Rating y user_id de cada pelicula para no buscar mas en el DataFrame\n",
    "            self.dicPelis[film]=self.df.ix[self.df['movie_id']==film,['rating','user_id']].sort(ascending=False,columns='rating') #Ordre Rating\n",
    "\n",
    "    def precompute(self, num):\n",
    "        \"\"\"Prepare data structures for estimation. Compute similarity matrix self.sim\"\"\"\n",
    "        #Iterar el dataframe con iterrrows()\n",
    "        diag = 1 # indice que ara la diagonal de la tabla ya que la matriz es simetrica\n",
    "        # Guardamos en col todos los indices. Como la matriz es simetrica tan solo recorremos \n",
    "        # las posiciones superiores de la diagonal ya que las posiciones inferiores tendrn el mismo\n",
    "        # valor, tan solo hemos de invertir x e y.\n",
    "        for x, col in self.sim.iterrows(): \n",
    "            for y in col.index.values[diag:]: \n",
    "                var=self.sim_method(self.df,x,y) #hacer el calculo de person\n",
    "                self.sim.set_value(x,y,var) #Guardar el valor en la tabla de similitudes\n",
    "                self.sim.set_value(y,x,var) #Guardar el valor invirtiendo las coordenadas\n",
    "            diag += 1\n",
    "        \n",
    "        if num == 1:\n",
    "            #self.sim.save(\"MatrixUser\") #Guardar la taula de similituts a disc\n",
    "            print 1\n",
    "        else:\n",
    "            print 2\n",
    "            #self.sim.save(\"ItemBased\") #Guardar la tabla a disco para su posterior recuperacion\n",
    "            \n",
    "    def estimate(self, row, col, num):\n",
    "        \"\"\" Given an row (user_id in 6, movie_id in 7) and a column (movie_id in 6, user_id in 7) \n",
    "            returns the estimated rating \"\"\"\n",
    "        if num == 1:\n",
    "            # Si el usuario no existe retornamos np.NAN\n",
    "            if row not in self.dicUser or col not in self.dicPelis:\n",
    "                return np.NAN,' El usuario no existe'\n",
    "            #Al tener que cargar varias veces por id de movie se usa el diccionario de peliculas para agilizar la carga\n",
    "            pearsonUser = [self.sim.loc[row,user]  for user in self.dicPelis[col]['user_id']]\n",
    "            ratingMovie = [rating for rating in self.dicPelis[col]['rating']]\n",
    "            #estimate rating\n",
    "            sumPearsonXRating = sum(np.multiply(pearsonUser,ratingMovie))\n",
    "            sumPears = sum(pearsonUser)\n",
    "            #Filtro para evitar valores nan y los divisores con valor absoluto entre 0 i 0,5 ya que generan errores\n",
    "            if(sumPearsonXRating == 0 or abs(sumPears) < 0.5):\n",
    "                return 3;\n",
    "            out=int(round(sumPearsonXRating/sumPears))\n",
    "            if out> 5: #Filtro para no sacar un valor superior a 5 ya que por el redondeo puede salir valor mas alto\n",
    "                return 5\n",
    "            else:\n",
    "                return out\n",
    "        else:\n",
    "            # Si la pelicula no existe retornamos np.NAN\n",
    "            if row not in self.dicUser or col not in self.dicPelis:\n",
    "                return np.NAN\n",
    "            #Al tener que hacer varias consultas sobre el mismo usuario se usa un diccionario para no perder mucho tiempo buscando en el dataFrame\n",
    "            pearsonMovie = [self.sim.loc[col,movie]  for movie in self.dicUser[row]['movie_id']]\n",
    "            ratingMovie = [rating for rating in self.dicUser[row]['rating']]#Covertir en una lista todas las puntuacions \n",
    "            #estimate rating\n",
    "            sumPearsonXRating = sum(np.multiply(pearsonMovie,ratingMovie))\n",
    "            sumPears = sum(pearsonMovie)\n",
    "            #Se filtra el valor absolut de sumPears ya que si el valor esta entre 0 y 0.5 genera error\n",
    "            if(sumPearsonXRating == 0 or abs(sumPears) < 0.5):\n",
    "                return 3;\n",
    "            out=int(round(sumPearsonXRating/sumPears))\n",
    "            if out > 5: #Filtro por si el valor tiene numeros decimales que lo sacan de la escala\n",
    "                return 5;\n",
    "            else:\n",
    "                return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UserRecomender(CollaborativeFiltering):\n",
    "    \"\"\" Recomender using Collaborative filtering with a User similarity (u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, data_train, similarity=sim_pearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        \n",
    "        # You should do any transformation to data_train (grouping/pivot/...) here, if needed\n",
    "        transformed_data = data_train\n",
    "        \n",
    "        super(UserRecomender, self).__init__(transformed_data, data_train.user_id.unique(), similarity)\n",
    "\n",
    "                \n",
    "    def estimate(self, user_id, movie_id):\n",
    "        \"\"\" Given an user_id and a movie_id returns the estimated rating for such movie \"\"\"\n",
    "        return super(UserRecomender, self).estimate(user_id, movie_id, 1)\n",
    "        \n",
    "    #Exercici 8\n",
    "    def get_recomendations(self, user_id, n): #Nou metode per el Ex 8\n",
    "        out=[]\n",
    "        x=0\n",
    "        vistes=self.dicUser[user_id] #Peliculas ya vistas por el usuario\n",
    "        #Se eliminan usuarios con valor negativo o proximo al 0 y se ordenan para asi ir obteniendo ha que usuarios consultar primero\n",
    "        ids=list(self.sim.ix[self.sim[user_id]>0.50,user_id].order(ascending=False).index.values) #llista dels millors candidats\n",
    "        numus=len(ids) #numero de candidatos\n",
    "        while(x<numus):\n",
    "            #Filtrage de peliculas con puntuacion de 5 de un usuario, però en caso que ningun usuario puntue con 5 seria intresante bajar este tope\n",
    "            millors=list(self.df.ix[(self.df['user_id']==ids[x]) & (self.df['rating']>4)].sort(ascending=False,columns='rating')['movie_id'])\n",
    "            iguals=set(millors) & set(vistes) #Se compruevan si estan repetidas las peliculas para llenar las lista con valores unicos\n",
    "            for elim in iguals:\n",
    "                millors.remove(elim)#Se eliminan las peliculas repetidas\n",
    "            out.extend(millors) #añadir las peliculas a la lista de salida\n",
    "            out=list(set(out))#Eliminar posibles repeticiones\n",
    "            if(len(out)>n):\n",
    "                return out[:n] #Retorna la lista de n peliculas recomendadas\n",
    "            x=x+1 #siguiente usuario\n",
    "        \n",
    "        return out #En caso de no tener mas referencia devuelve todo lo guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orla_\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:15: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "C:\\Users\\orla_\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:20: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_reco = UserRecomender(movielens_train)\n",
    "user_reco.precompute(1)\n",
    "user_reco.estimate(user_id=2, movie_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set an array element with a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-307-3d21429e3f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_reco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovielens_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-99-fc7820afed7c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(estimate, test)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmovielens_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mids_to_estimate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'movie_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mestimated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mids_to_estimate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mreal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set an array element with a sequence"
     ]
    }
   ],
   "source": [
    "evaluate(user_reco.estimate, movielens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 7\n",
    "\n",
    "+ Desenvolupa un sistema de recomanació col·laboratiu basat en ítems. Si la classe `CollaborativeFiltering` s'ha fet prou genèrica, tan sols caldrà fer petites modificacions a `__init__`, del contrari, podeu fer les modificacions que cregueu necessàries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ItemRecomender(CollaborativeFiltering):\n",
    "    \"\"\" Recomender using Collaborative filtering with a Item similarity (i,i'). \"\"\"\n",
    "    \n",
    "    def __init__(self,data_train, similarity=sim_pearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        \n",
    "        # You should do any transformation to data_train (grouping/pivot/...) here, if needed\n",
    "        transformed_data = data_train\n",
    "        \n",
    "        super(ItemRecomender, self).__init__(transformed_data, data_train.movie_id.unique(), similarity)\n",
    "\n",
    "            \n",
    "    def estimate(self, user_id, movie_id):\n",
    "        \"\"\" Given an user_id and a movie_id returns the estimated rating for such movie \"\"\"\n",
    "        return super(ItemRecomender, self).estimate(movie_id, user_id, 0)\n",
    "    \n",
    "    def get_recomendations(self, user_id, n): \n",
    "        out=[]\n",
    "        i,x=0,0\n",
    "        vistas=list(self.dicUser[user_id].movie_id.unique()) #Array de peliculas ya vistas por el usuario\n",
    "        #Comentar que se ha puesto que busque las notas superiores al tres porque puede que no haya puntuado un 5\n",
    "        Pelis=np.array(data.ix[(data['user_id']==user_id) & (data['rating']>3)].sort(ascending=False,columns='rating')['movie_id'])\n",
    "        numPelis=len(Pelis)\n",
    "        #Se iteran las peliculas con referencia a las de la lista de similitudes\n",
    "        while(x<numPelis):\n",
    "            #Extraer las peliculas con un valor de similitud muy alto\n",
    "            #Si no se obtiene peliculas se tendria que bajar el nivel de similitud para mostrar peliculas\n",
    "            Reco=list(self.sim.ix[self.sim[Pelis[x]]>0.50,Pelis[x]].order(ascending=False).index.values)\n",
    "            iguals=set(Reco) & set(vistas) #Eliminar las peliculas iguales en las dos listas\n",
    "            for elim in iguals:\n",
    "                Reco.remove(elim) #Eliminar las peliculas iguales para que las que hayan en out sean unicas y no vistas\n",
    "            out.extend(Reco)#Se añaden a la lista de salia quitando los ids repetidos\n",
    "            out=list(set(out))#Se quitan los valores repetidos\n",
    "            if(len(out)>n):\n",
    "                return out[:n] #Devuelve los n valores\n",
    "            x=x+1 #Siguiente pelicula\n",
    "        return out  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orla_\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:15: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "C:\\Users\\orla_\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:20: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_reco = ItemRecomender(movielens_train)\n",
    "item_reco.precompute(0)\n",
    "item_reco.estimate(user_id=2, movie_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4591203713417602"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(item_reco.estimate, movielens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 8\n",
    "\n",
    "* Feu un nou mètode `get_recomendations(user_id, n)` que retorni les n pel·lícules recomenades per a l'usuari user_id. De nou, és recomenable fer-ho a la clase pare, `CollaborativeFiltering`, cridant-la des dels fills de forma semblant a com fa `estimate`.\n",
    "\n",
    "* Executeu la funció en els dos recomenadors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orla_\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:23: FutureWarning: order is deprecated, use sort_values(...)\n",
      "C:\\Users\\orla_\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:27: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 34, 36, 17, 50]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_reco.get_recomendations(8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orla_\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:22: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "C:\\Users\\orla_\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:28: FutureWarning: order is deprecated, use sort_values(...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[34, 35, 36, 6, 73]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_reco.get_recomendations(1, 5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

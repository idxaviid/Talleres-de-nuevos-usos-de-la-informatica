{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressió Logística\n",
    "\n",
    "**Nom**: Xavi Cano && Orlando Manjarrez\n",
    "\n",
    "La **regressió logística** és un tipus d'algorisme de classificació binària (vol predir un valor $0$ o $1$ per una determinada mostra) i per fer-ho fa servir la funció logística:\n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1+ e^{-x}}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFdCAYAAACJlf6EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+vxw4seS3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd85d006150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def logistic(x):\n",
    "    return 1.0 / (1 + math.exp(-x))\n",
    "\n",
    "x = np.linspace(-10,10,200)\n",
    "y = [logistic(_) for _ in x]\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1,1.1])\n",
    "plt.plot(x,y,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si disposem d'un conjunt de punts $\\{(x_i, y_i)\\}$, on $y_i \\in \\{0,1\\}$, i volem trobar quina és la probabilitat d'una mostra de ser $0$ o $1$ podem aproximar la probabilitat d'aquesta manera:\n",
    "\n",
    "$$ \\hat{y}_i = \\sigma(w x_i) $$\n",
    "\n",
    "on $w$ són una sèrie de pesos que cal determinar. En el cas de la regressió logísitica, la funció de cost que MAXIMITZAREM és la funció que s'anomena *log likelihood*:\n",
    "\n",
    "$$ logL = y_i \\log \\sigma(w x_i) + (1- y_i) \\log (1 - \\sigma(w x_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dot(v, w):\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def logistic_log_likelihood_i(x_i, y_i, beta):\n",
    "    if y_i == 1:\n",
    "        return math.log(logistic(dot(x_i, beta)))\n",
    "    else:\n",
    "        return math.log(1 - logistic(dot(x_i, beta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per tant, la funció de cost és:\n",
    "\n",
    "$$ \\sum_{x_i, y_i} y_i \\log \\sigma(w x_i) + (1- y_i) \\log (1 - \\sigma(w x_i)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_log_likelihood(x, y, beta):\n",
    "    return sum(logistic_log_likelihood_i(x_i, y_i, beta)\n",
    "               for x_i, y_i in zip(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Les derivades d'aquestes funcions són simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_log_partial_ij(x_i, y_i, beta, j):\n",
    "    \"\"\"j es l'index de la derivada\"\"\"\n",
    "    return (y_i - logistic(dot(x_i, beta))) * x_i[j]\n",
    "    \n",
    "def logistic_log_gradient_i(x_i, y_i, beta):\n",
    "    \"\"\"gradient de log likelihood pel punt i\"\"\"\n",
    "    return [logistic_log_partial_ij(x_i, y_i, beta, j)\n",
    "            for j, _ in enumerate(beta)]\n",
    "            \n",
    "def logistic_log_gradient(x, y, beta):\n",
    "    return reduce(vector_add,\n",
    "                  [logistic_log_gradient_i(x_i, y_i, beta)\n",
    "                   for x_i, y_i in zip(x,y)])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amb això, i algunes funcions auxililars, tenim tots els ingredients per plantejar el problema com un problema d'optimització."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funcions auxiliars\n",
    "from functools import partial\n",
    "\n",
    "def split_data(data, prob):\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "def train_test_split(x, y, test_pct):\n",
    "    data = zip(x, y)                                \n",
    "    train, test = split_data(data, 1 - test_pct)  \n",
    "    x_train, y_train = zip(*train)                \n",
    "    x_test, y_test = zip(*test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def maximize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    return minimize_batch(negate(target_fn),\n",
    "                          negate_all(gradient_fn),\n",
    "                          theta_0, \n",
    "                          tolerance)\n",
    "\n",
    "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    \n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    theta = theta_0                           # set theta to initial value\n",
    "    target_fn = safe(target_fn)               # safe version of target_fn\n",
    "    value = target_fn(theta)                  # value we're minimizing\n",
    "    \n",
    "    while True:\n",
    "        gradient = gradient_fn(theta)  \n",
    "        next_thetas = [step(theta, gradient, -step_size)\n",
    "                       for step_size in step_sizes]\n",
    "                   \n",
    "        # choose the one that minimizes the error function        \n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_theta)\n",
    "        \n",
    "        # stop if we're \"converging\"\n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return theta\n",
    "        else:\n",
    "            theta, value = next_theta, next_value\n",
    "            \n",
    "def rescale(data_matrix):\n",
    "    means, stdevs = scale(data_matrix)\n",
    "\n",
    "    def rescaled(i, j): \n",
    "        if stdevs[j] > 0:\n",
    "            return (data_matrix[i][j] - means[j]) / stdevs[j]\n",
    "        else:\n",
    "            return data_matrix[i][j]\n",
    "\n",
    "    num_rows, num_cols = shape(data_matrix)\n",
    "    return make_matrix(num_rows, num_cols, rescaled)\n",
    "\n",
    "def scale(data_matrix):\n",
    "    num_rows, num_cols = shape(data_matrix)\n",
    "    means = [mean(get_column(data_matrix,j))\n",
    "             for j in range(num_cols)]\n",
    "    stdevs = [standard_deviation(get_column(data_matrix,j))\n",
    "              for j in range(num_cols)]\n",
    "    return means, stdevs\n",
    "\n",
    "def shape(A):\n",
    "    num_rows = len(A)\n",
    "    num_cols = len(A[0]) if A else 0\n",
    "    return num_rows, num_cols\n",
    "\n",
    "def mean(x): \n",
    "    return sum(x) / len(x)\n",
    "\n",
    "def get_column(A, j):\n",
    "    return [A_i[j] for A_i in A]\n",
    "\n",
    "def variance(x):\n",
    "    n = len(x)\n",
    "    deviations = de_mean(x)\n",
    "    return sum_of_squares(deviations) / (n - 1)\n",
    "    \n",
    "def standard_deviation(x):\n",
    "    return math.sqrt(variance(x))\n",
    "\n",
    "def de_mean(x):\n",
    "    x_bar = mean(x)\n",
    "    return [x_i - x_bar for x_i in x]\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    \"\"\"v_1 * v_1 + ... + v_n * v_n\"\"\"\n",
    "    return dot(v, v)\n",
    "\n",
    "def make_matrix(num_rows, num_cols, entry_fn):\n",
    "    \"\"\"returns a num_rows x num_cols matrix \n",
    "    whose (i,j)-th entry is entry_fn(i, j)\"\"\"\n",
    "    return [[entry_fn(i, j) for j in range(num_cols)]\n",
    "            for i in range(num_rows)]  \n",
    "\n",
    "def entry_fn(i, j): return A[i][j] + B[i][j]\n",
    "\n",
    "def negate(f):\n",
    "    \"\"\"return a function that for any input x returns -f(x)\"\"\"\n",
    "    return lambda *args, **kwargs: -f(*args, **kwargs)\n",
    "\n",
    "def negate_all(f):\n",
    "    \"\"\"the same when f returns a list of numbers\"\"\"\n",
    "    return lambda *args, **kwargs: [-y for y in f(*args, **kwargs)]\n",
    "\n",
    "def safe(f):\n",
    "    \"\"\"define a new function that wraps f and return it\"\"\"\n",
    "    def safe_f(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            return float('inf')         # this means \"infinity\" in Python\n",
    "    return safe_f\n",
    "\n",
    "def vector_add(v, w):\n",
    "    \"\"\"adds two vectors componentwise\"\"\"\n",
    "    return [v_i + w_i for v_i, w_i in zip(v,w)]\n",
    "\n",
    "def step(v, direction, step_size):\n",
    "    \"\"\"move step_size in the direction from v\"\"\"\n",
    "    return [v_i + step_size * direction_i\n",
    "            for v_i, direction_i in zip(v, direction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les dades que farem servir corresponen a una base de dades de 200 usuaris i contenen els seus anys d'experiència, el seu salari i el resultat d'una avaluació interna ($0$ o $1$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.7, 48000], [1, 1.9, 48000]] [1, 0]\n"
     ]
    }
   ],
   "source": [
    "data = [(0.7,48000,1),(1.9,48000,0),(2.5,60000,1),(4.2,63000,0),(6,76000,0),(6.5,69000,0),(7.5,76000,0), \\\n",
    "        (8.1,88000,0),(8.7,83000,1),(10,83000,1),(0.8,43000,0),(1.8,60000,0),(10,79000,1),(6.1,76000,0), \\\n",
    "        (1.4,50000,0),(9.1,92000,0),(5.8,75000,0),(5.2,69000,0),(1,56000,0),(6,67000,0),(4.9,74000,0),   \\\n",
    "        (6.4,63000,1),(6.2,82000,0),(3.3,58000,0),(9.3,90000,1),(5.5,57000,1),(9.1,102000,0),(2.4,54000,0),\\\n",
    "        (8.2,65000,1),(5.3,82000,0),(9.8,107000,0),(1.8,64000,0),(0.6,46000,1),(0.8,48000,0),(8.6,84000,1),\\\n",
    "        (0.6,45000,0),(0.5,30000,1),(7.3,89000,0),(2.5,48000,1),(5.6,76000,0),(7.4,77000,0),(2.7,56000,0),\\\n",
    "        (0.7,48000,0),(1.2,42000,0),(0.2,32000,1),(4.7,56000,1),(2.8,44000,1),(7.6,78000,0),(1.1,63000,0),\\\n",
    "        (8,79000,1),(2.7,56000,0),(6,52000,1),(4.6,56000,0),(2.5,51000,0),(5.7,71000,0),(2.9,65000,0), \\\n",
    "        (1.1,33000,1),(3,62000,0),(4,71000,0),(2.4,61000,0),(7.5,75000,0),(9.7,81000,1),(3.2,62000,0),\\\n",
    "        (7.9,88000,0),(4.7,44000,1),(2.5,55000,0),(1.6,41000,0),(6.7,64000,1),(6.9,66000,1),(7.9,78000,1),\\\n",
    "        (8.1,102000,0),(5.3,48000,1),(8.5,66000,1),(0.2,56000,0),(6,69000,0),(7.5,77000,0),(8,86000,0),\\\n",
    "        (4.4,68000,0),(4.9,75000,0),(1.5,60000,0),(2.2,50000,0),(3.4,49000,1),(4.2,70000,0),(7.7,98000,0),\\\n",
    "        (8.2,85000,0),(5.4,88000,0),(0.1,46000,0),(1.5,37000,0),(6.3,86000,0),(3.7,57000,0),(8.4,85000,0),\\\n",
    "        (2,42000,0),(5.8,69000,1),(2.7,64000,0),(3.1,63000,0),(1.9,48000,0),(10,72000,1),(0.2,45000,0),\\\n",
    "        (8.6,95000,0),(1.5,64000,0),(9.8,95000,0),(5.3,65000,0),(7.5,80000,0),(9.9,91000,0),(9.7,50000,1),\\\n",
    "        (2.8,68000,0),(3.6,58000,0),(3.9,74000,0),(4.4,76000,0),(2.5,49000,0),(7.2,81000,0),(5.2,60000,1),\\\n",
    "        (2.4,62000,0),(8.9,94000,0),(2.4,63000,0),(6.8,69000,1),(6.5,77000,0),(7,86000,0),(9.4,94000,0),\\\n",
    "        (7.8,72000,1),(0.2,53000,0),(10,97000,0),(5.5,65000,0),(7.7,71000,1),(8.1,66000,1),(9.8,91000,0),\\\n",
    "        (8,84000,0),(2.7,55000,0),(2.8,62000,0),(9.4,79000,0),(2.5,57000,0),(7.4,70000,1),(2.1,47000,0),\\\n",
    "        (5.3,62000,1),(6.3,79000,0),(6.8,58000,1),(5.7,80000,0),(2.2,61000,0),(4.8,62000,0),(3.7,64000,0),\\\n",
    "        (4.1,85000,0),(2.3,51000,0),(3.5,58000,0),(0.9,43000,0),(0.9,54000,0),(4.5,74000,0),(6.5,55000,1),\\\n",
    "        (4.1,41000,1),(7.1,73000,0),(1.1,66000,0),(9.1,81000,1),(8,69000,1),(7.3,72000,1),(3.3,50000,0),\\\n",
    "        (3.9,58000,0),(2.6,49000,0),(1.6,78000,0),(0.7,56000,0),(2.1,36000,1),(7.5,90000,0),(4.8,59000,1),\\\n",
    "        (8.9,95000,0),(6.2,72000,0),(6.3,63000,0),(9.1,100000,0),(7.3,61000,1),(5.6,74000,0),(0.5,66000,0),\\\n",
    "        (1.1,59000,0),(5.1,61000,0),(6.2,70000,0),(6.6,56000,1),(6.3,76000,0),(6.5,78000,0),(5.1,59000,0),\\\n",
    "        (9.5,74000,1),(4.5,64000,0),(2,54000,0),(1,52000,0),(4,69000,0),(6.5,76000,0),(3,60000,0),(4.5,63000,0),\\\n",
    "        (7.8,70000,0),(3.9,60000,1),(0.8,51000,0),(4.2,78000,0),(1.1,54000,0),(6.2,60000,0),(2.9,59000,0),\\\n",
    "        (2.1,52000,0),(8.2,87000,0),(4.8,73000,0),(2.2,42000,1),(9.1,98000,0),(6.5,84000,0),(6.9,73000,0),\\\n",
    "        (5.1,72000,0),(9.1,69000,1),(9.8,79000,1),]\n",
    "data = map(list, data)              # canviem de tuples a llistes\n",
    "x = [[1] + row[:2] for row in data] # cada element es [1, experiencia, salari]\n",
    "y = [row[2] for row in data]        # cada element es resultat\n",
    "print x[0:2], y[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fet de posar una de les components de $x_i$ a $1$ ens permet que el model lineal que usem pugui ser del tipus $w_0 + w_1 x_1 + w_2 x_2$, atès que $x_0 = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat [-1.9061824826642335, 4.053083869380028, -3.878895361783912]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "rescaled_x = rescale(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(rescaled_x, y, 0.33)\n",
    "\n",
    "# want to maximize log likelihood on the training data\n",
    "fn = partial(logistic_log_likelihood, x_train, y_train)\n",
    "gradient_fn = partial(logistic_log_gradient, x_train, y_train)\n",
    "\n",
    "# pick a random starting point\n",
    "w_0 = [1, 1, 1]\n",
    "\n",
    "# and maximize using gradient descent\n",
    "w_hat = maximize_batch(fn, gradient_fn, w_0)\n",
    "\n",
    "print \"w_hat\", w_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 1\n",
    "\n",
    "Avalua el resultat anterior en termes de 'precision' i 'recall'. Consulteu https://en.wikipedia.org/wiki/Precision_and_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado de evaluar la funcion anterior es:\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n"
     ]
    }
   ],
   "source": [
    "# Solució\n",
    "\n",
    "def evaluate(x_test,y_test,w_hat):\n",
    "    #Ponemos los contadores todos a cero\n",
    "    CiertoPositivo = 0\n",
    "    FalsoPositivo = 0\n",
    "    CiertoNegativo = 0\n",
    "    FalsoNegativo = 0\n",
    "    resTotal=[]\n",
    "    for i in range(len(x_test)):\n",
    "        #En este punto usamos la funcion logistica\n",
    "        res = logistic(x_test[i][0]*w_hat[0]+x_test[i][1]*w_hat[1]+x_test[i][2]*w_hat[2])\n",
    "        #Añadimos el resultado de la funcion anterior a la lista\n",
    "        resTotal.append(res)\n",
    "        if res > 0.5:#Comprovamos si el resultado es mayor que 0.5, si es cierto es de clase 1\n",
    "            clase = 1\n",
    "        else:#De lo contrario es de clase 0\n",
    "            clase = 0\n",
    "        \n",
    "        y = y_test[i] \n",
    "        #Aqui comparamos la clase con el valor real, en caso de ser igual incrementamos el contador de TP\n",
    "        if clase == 1 and y == 1: \n",
    "            CiertoPositivo +=1 \n",
    "        #Aqui comparamos la clase con el valor real, en caso de ser igual incrementamos el contador de FP\n",
    "        elif clase == 1 and y == 0:\n",
    "            FalsoPositivo +=1 \n",
    "        #Aqui comparamos la clase con el valor real, en caso de ser igual incrementamos el contador de FN\n",
    "        elif clase == 0 and y == 1:\n",
    "            FalsoNegativo +=1\n",
    "        #Sino incrementamos el contador de TN\n",
    "        else:\n",
    "            CiertoNegativo +=1\n",
    "    \n",
    "    #Calculamos el valor de precision\n",
    "    precision= float(CiertoPositivo)/float(CiertoPositivo+FalsoPositivo)\n",
    "    #Calculamos el valor de recall\n",
    "    recall = float(CiertoPositivo)/float(CiertoPositivo+FalsoNegativo)\n",
    "    return resTotal,precision,recall\n",
    "#Resultado final en terminos de precision y recall\n",
    "res, precision, recall = evaluate(x_test,y_test,w_hat)\n",
    "print \"El resultado de evaluar la funcion anterior es:\"\n",
    "print \"Precision:\" , \"{0:.2f}\".format(precision*100),\"%\"\n",
    "print \"Recall:\", \"{0:.2f}\".format(recall*100),\"%\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 2\n",
    "\n",
    "Feu un gràfic en que l'eix $x$ representi el valor de les prediccions i el $y$ els valors reals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFdCAYAAACNYC65AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd85c96d210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solució\n",
    "\n",
    "#Aqui decimos que el eje x sea nuestro resultado anterior, es decir el valor de las predicciones\n",
    "x = res \n",
    "# Y aqui lo mismo con el eje y, pero le decimos que sean los valores reales\n",
    "y = y_test\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Dibujamos la grafica\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1,1.1])\n",
    "plt.plot(x,y,'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 3\n",
    "\n",
    "El cas anterior surt d'un nombre random fix (random.seed(0)) i d'un paràmetre fix ([1,1,1]). Feu una cerca aleatoria a veure si es pot trobar un `w_hat` sensiblement millor al [-1.9061824826642335, 4.053083869380028, -3.878895361783912]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion: 0\n",
      "Valor w_0: [1.6285754255803098, 0.03874549938810534, 6.546275765234981]\n",
      "Valor w_hat: [-1.9062193412449109, 4.053240656781194, -3.878947618509633]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 1\n",
      "Valor w_0: [1.4040698903568194, 7.866793455760521, 6.80503995881725]\n",
      "Valor w_hat: [-1.9060850810415817, 4.053350501382371, -3.8780485133542513]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 2\n",
      "Valor w_0: [9.706757933544957, 3.965144869518913, 9.213919134510528]\n",
      "Valor w_hat: [-1.9062210051527182, 4.0537734665680665, -3.8784029340843094]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 3\n",
      "Valor w_0: [4.5370417231953315, 3.3950373983620707, 1.0233886991705377]\n",
      "Valor w_hat: [-1.90625730812558, 4.053294538148224, -3.8791135356628237]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 4\n",
      "Valor w_0: [8.828321850718597, 7.947901585625869, 3.2292897653506056]\n",
      "Valor w_hat: [-1.9084182609071871, 4.060183297231486, -3.8845742514806627]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 5\n",
      "Valor w_0: [4.557443849256289, 3.2514346581324824, 0.28829116538094723]\n",
      "Valor w_hat: [-1.9061560768720853, 4.053544902714575, -3.8782612247749046]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 6\n",
      "Valor w_0: [0.4435252539911694, 3.687041258820589, 2.095913281287837]\n",
      "Valor w_hat: [-1.9061659202254406, 4.053550906470372, -3.8783125737323636]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 7\n",
      "Valor w_0: [5.245146032105923, 1.877850356496189, 2.016215864664097]\n",
      "Valor w_hat: [-1.9062665421581961, 4.05338576462918, -3.879072560596212]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 8\n",
      "Valor w_0: [6.726678813176303, 7.356026567617159, 3.1223209587410494]\n",
      "Valor w_hat: [-1.9062088486072193, 4.053678067434376, -3.878431141184117]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n",
      "Iteracion: 9\n",
      "Valor w_0: [8.599943994333726, 2.546391746557106, 3.4394037628155716]\n",
      "Valor w_hat: [-1.9062446383204468, 4.0532641265519755, -3.8790711181974893]\n",
      "Precision: 93.33 %\n",
      "Recall: 82.35 %\n"
     ]
    }
   ],
   "source": [
    "# Solució\n",
    "\n",
    "import random\n",
    "for i in range(10):\n",
    "    #Creamos un vector de 3 valores aleatorios entre 0 i 10\n",
    "    w_0 = [random.uniform(0.0,10.0), random.uniform(0.0,10.0), random.uniform(0.0,10.0)]\n",
    "    #Aqui guardamos el nuevo valor w_hat\n",
    "    w_hat = maximize_batch(fn, gradient_fn, w_0)\n",
    "    print \"Iteracion:\",i\n",
    "    print \"Valor w_0:\", w_0\n",
    "    print \"Valor w_hat:\",w_hat\n",
    "    #Aqui evaluamos el nuevo w_hat y obtenemos la precision y el recall de los nuevos valores\n",
    "    res, precision, recall = evaluate(x_test,y_test,w_hat)\n",
    "    #Los valores de precision y recall siempre son los mismos, el valor de w_hat varia muy poco\n",
    "    print \"Precision:\" , \"{0:.2f}\".format(precision*100),\"%\"\n",
    "    print \"Recall:\", \"{0:.2f}\".format(recall*100),\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
